{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNModel(object):\n",
    "    def __init__(self, batch_size = 50, learning_rate = 1e-4, dropout_rate = 0.5):\n",
    "        # 因为最后的节点数受stride的影响，具体结构牵一发而懂全身，所以层数和节点数不作为输入设置\n",
    "        # 在这个例子中，图片初始为28*28，cnn的stride为[1, 1, 1, 1]图片大小维持不变，pool的stride为[1, 2, 2, 1]，导致缩水一半，\n",
    "        # 全部经历2个cnn和2个pool，所以最终得到的图片为7*7.\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate # 如果需要调整的话，应该使用tf.Variable\n",
    "        self.dropout_rate = dropout_rate \n",
    "        self.global_step = tf.Variable(0, trainable = False)\n",
    "        \n",
    "        def _w_variable(shape):\n",
    "            tmp = tf.truncated_normal(shape, stddev = 0.1)\n",
    "            return tf.Variable(tmp)\n",
    "        def _b_variable(shape):\n",
    "            tmp = tf.constant(0.1, shape = shape)\n",
    "            return tf.Variable(tmp)\n",
    "        def _conv2d(x, w):\n",
    "            return tf.nn.conv2d(x, w, strides = [1, 1, 1, 1], padding = \"SAME\")\n",
    "        def _max_pool_2X2(x):\n",
    "            return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "        def _cnn_model(input_images, dropout_rate = 0.5):\n",
    "            # 一个in_channel到一个out_channel只能由一种特征提取，\n",
    "            # filter的4D分别表示[filter_height, filter_width, in_channel, out_channel]\n",
    "            # 注意和input的区别：[batch, in_height, in_width, in_channels]这里是[1, 28, 28, 1]\n",
    "            w_conv1 = _w_variable([5, 5, 1, 32])\n",
    "            w_conv2 = _w_variable([5, 5, 32, 64])\n",
    "            w_fc1 = _w_variable([7*7*64, 1024])\n",
    "            w_fc2 = _w_variable([1024, 10])\n",
    "            b_conv1 = _b_variable([32])\n",
    "            b_conv2 = _b_variable([64])\n",
    "            b_fc1 = _b_variable([1024])\n",
    "            b_fc2 = _b_variable([10])\n",
    "            # 让我感到奇怪的是，tf.nn.conv2d的输出怎么会是[32]类型的，不是same type as input吗，\n",
    "            # 所以他应该是[1, 28, 28, 32]吧。那么他和b_conv1是怎么相加的。回去看一下tensor相加，也许能够找到答案\n",
    "            h_conv1 = tf.nn.relu(_conv2d(input_images, w_conv1) + b_conv1)\n",
    "            h_pool1 = _max_pool_2X2(h_conv1)\n",
    "            h_conv2 = tf.nn.relu(_conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "            h_pool2 = _max_pool_2X2(h_conv2)\n",
    "            # reshape然后接两个全连接层，然后输出，中间加一个dropout以避免Overfitting, 为什么不softmax呢？？\n",
    "            # relu的输出应该不保证小于1的说。 可结果表明效果不错，为什么？？？\n",
    "            # 是下面算loss的算法里面，调用了吗？？\n",
    "            h_pool2_flat = tf.reshape([-1, 7 * 7 * 64])\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, dropout_rate)\n",
    "            y_conv = tf.nn.relu(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)\n",
    "            return y_conv\n",
    "        # 核心模型已经有了，接下来是设置饲料，包括image和label\n",
    "        # 为什么要用tf.float类型的呢数据吗\n",
    "        input_data = tf.placeholder(tf.float32, [None, 28 * 28])\n",
    "        input_images = tf.reshape(input_data, [-1, 28, 28, 1])\n",
    "        input_labels = tf.placeholder(tf.float32, [None, 10])\n",
    "        # 然后用cross_entropy计算loss, 用adamOptimizer进行优化\n",
    "        y_conv = _cnn_model(input_images)\n",
    "        self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(label = input_labels, logits = y_conv))\n",
    "        self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(cross_entropy)\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(input_labels, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 一次就一个结果，怎么mean？？？\n",
    "        # set global_step\n",
    "        tmp_step = tf.add(self.global_step, tf.constant(1))\n",
    "        update = tf.assign(self.global_step, tmp_step)\n",
    "        # 获取saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "    \n",
    "    def step(self, session, input_data, input_labels):\n",
    "        # 用给定的输入，训练模型\n",
    "        count = len(input_data)\n",
    "        for _ in range(count - 1):\n",
    "            session.run(self.train_step, feed_dict = {input_data : input_data, input_labels : input_labels})\n",
    "            session.run(update)\n",
    "        session.run(update)\n",
    "        return session.run(self.cross_entropy, feed_dict = {input_data: input_data, input_labels: input_labels})\n",
    "        \n",
    "    def evaluate(self, session, input_data, input_labels):\n",
    "        return self.accuracy.eval(feed_dict = {input_data : input_data, input_labels : input_labels}, session = session)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 还差了一个getbatch() 写到runner里面了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
